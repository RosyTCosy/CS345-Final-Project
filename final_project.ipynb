{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook is part of  course materials for CS 345: Machine Learning Foundations and Practice at Colorado State University.\n",
    "Original versions were created by Asa Ben-Hur and updated by Ross Beveridge.\n",
    "The content is availabe [on GitHub](https://github.com/asabenhur/CS345).*\n",
    "\n",
    "*The text is released under the [CC BY-SA license](https://creativecommons.org/licenses/by-sa/4.0/), and code is released under the [MIT license](https://opensource.org/licenses/MIT).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github//asabenhur/CS345/blob/master/fall24/notebooks/module01_06_perceptron.ipynb\">\n",
    "  <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqH586mbfovv"
   },
   "source": [
    "# Predicting Valorant Match Outcomes Using Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Hallie Gurr and Rose Ordway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "#Helper functions\n",
    "def removeNanRows(X):\n",
    "    df = pd.DataFrame(X)\n",
    "    df = df.dropna()\n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name\n",
      "0          Matches\n",
      "1            Games\n",
      "2      Game_Rounds\n",
      "3  Game_Scoreboard\n"
     ]
    }
   ],
   "source": [
    "#Database connection\n",
    "db_path = \"data/valorant.sqlite\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Check existing tables names\n",
    "tables = pd.read_sql_query(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table';\", conn\n",
    ")\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147702, 9)\n",
      "        Kills  Deaths  Assists  HS_Percent  Econ  Duelist  Controller  \\\n",
      "0        24.0    10.0      3.0        0.31  74.0      1.0         1.0   \n",
      "1        16.0    10.0      7.0        0.16  67.0      1.0         1.0   \n",
      "2        17.0     9.0      8.0        0.27  58.0      1.0         1.0   \n",
      "3        17.0    12.0      2.0        0.19  48.0      1.0         1.0   \n",
      "4         5.0    13.0      3.0        0.22  21.0      1.0         1.0   \n",
      "...       ...     ...      ...         ...   ...      ...         ...   \n",
      "147697   13.0    12.0      1.0        0.18  61.0      2.0         1.0   \n",
      "147698    4.0    13.0      4.0        0.33  32.0      2.0         1.0   \n",
      "147699    4.0    15.0      0.0        0.13  21.0      2.0         1.0   \n",
      "147700    3.0    14.0      4.0        0.19  29.0      2.0         1.0   \n",
      "147701    3.0    14.0      2.0        0.12  18.0      2.0         1.0   \n",
      "\n",
      "        Initiator  Sentinel  \n",
      "0             2.0       1.0  \n",
      "1             2.0       1.0  \n",
      "2             2.0       1.0  \n",
      "3             2.0       1.0  \n",
      "4             2.0       1.0  \n",
      "...           ...       ...  \n",
      "147697        1.0       1.0  \n",
      "147698        1.0       1.0  \n",
      "147699        1.0       1.0  \n",
      "147700        1.0       1.0  \n",
      "147701        1.0       1.0  \n",
      "\n",
      "[147702 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Get Scoreboard Data\n",
    "import pandas as pd\n",
    "ROLE_MAP = {\n",
    "    \"jett\": \"Duelist\",\n",
    "    \"raze\": \"Duelist\",\n",
    "    \"reyna\": \"Duelist\",\n",
    "    \"neon\": \"Duelist\",\n",
    "    \"yoru\": \"Duelist\",\n",
    "    \"phoenix\": \"Duelist\",\n",
    "\n",
    "    \"brimstone\": \"Controller\",\n",
    "    \"omen\": \"Controller\",\n",
    "    \"astra\": \"Controller\",\n",
    "    \"viper\": \"Controller\",\n",
    "    \"harbor\": \"Controller\",\n",
    "    \"clove\": \"Controller\",\n",
    "\n",
    "    \"sova\": \"Initiator\",\n",
    "    \"skye\": \"Initiator\",\n",
    "    \"breach\": \"Initiator\",\n",
    "    \"kayo\": \"Initiator\",\n",
    "    \"fade\": \"Initiator\",\n",
    "    \"gekko\": \"Initiator\",\n",
    "\n",
    "    \"sage\": \"Sentinel\",\n",
    "    \"killjoy\": \"Sentinel\",\n",
    "    \"cypher\": \"Sentinel\",\n",
    "    \"chamber\": \"Sentinel\",\n",
    "    \"deadlock\": \"Sentinel\",\n",
    "}\n",
    "\n",
    "def generateTeamCompList(scoreboard):\n",
    "    sb = scoreboard.copy()\n",
    "\n",
    "    sb[\"Role\"] = sb[\"Agent\"].map(ROLE_MAP)\n",
    "\n",
    "    sb_with_role = sb.dropna(subset=[\"Role\"])\n",
    "\n",
    "    comp = (\n",
    "        sb_with_role\n",
    "        .groupby([\"GameID\", \"TeamAbbreviation\", \"Role\"])\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "        .reindex(columns=[\"Duelist\", \"Controller\", \"Initiator\", \"Sentinel\"], fill_value=0)\n",
    "    )\n",
    "\n",
    "    return comp\n",
    "\n",
    "def getScoreboard(conn, limit=None):\n",
    "    #Looking at GameID, TeamAbbreviation, PlayerID, Agent, Kills, Deaths, Assists, HS_Percent, Econ\n",
    "    headers = [\"GameID\",\"TeamAbbreviation\", \"PlayerID\", \"Agent\", \"Kills\", \"Deaths\", \n",
    "           \"Assists\", \"HS_Percent\", \"Econ\"]\n",
    "\n",
    "    selections = \", \".join(headers)\n",
    "\n",
    "    conditions = \" AND \".join([f\"{h} IS NOT NULL\" for h in headers])\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT {selections}\n",
    "    FROM Game_Scoreboard\n",
    "    WHERE {conditions}\n",
    "    LIMIT {-1 if limit is None else limit};\n",
    "    \"\"\"\n",
    "    scoreboard = pd.read_sql_query(query, conn)\n",
    "    return scoreboard\n",
    "\n",
    "def MLScoreBoardData(conn, limit=None):\n",
    "    scoreboard = getScoreboard(conn, limit=limit)\n",
    "\n",
    "    df_teamcomp = generateTeamCompList(scoreboard) \n",
    "    scoreboard = assignTeamCompToScoreboard(scoreboard, df_teamcomp)\n",
    "\n",
    "    feature_cols = [\"Kills\", \"Deaths\", \"Assists\", \"HS_Percent\", \"Econ\",\n",
    "                    \"Duelist\", \"Controller\", \"Initiator\", \"Sentinel\"]\n",
    "    features = scoreboard[feature_cols].to_numpy()\n",
    "\n",
    "    X = removeNanRows(features)\n",
    "    return X\n",
    "\n",
    "def assignTeamCompToScoreboard(scoreboard, df_teamcomp):\n",
    "    df_teamcomp = df_teamcomp.reset_index() \n",
    "\n",
    "    merged = scoreboard.merge(\n",
    "        df_teamcomp,\n",
    "        on=[\"GameID\", \"TeamAbbreviation\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    return merged\n",
    "\n",
    "dataLimit = None\n",
    "mlscoreboard = MLScoreBoardData(conn, limit=dataLimit)\n",
    "print(mlscoreboard.shape)\n",
    "df = pd.DataFrame(mlscoreboard, columns=[\n",
    "    \"Kills\", \"Deaths\", \"Assists\", \"HS_Percent\", \"Econ\"\n",
    "] + [\"Duelist\", \"Controller\", \"Initiator\", \"Sentinel\"])\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 147702\n",
      "Number of entries with role: 147702\n",
      "Number of missing entries: 0\n",
      "Percent missing: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Some of the teams have less than 5 players (due to missing data) percent of missing players: \n",
    "# (I might have fixed this but I'm going to leave it for now)\n",
    "def getMissingPlayerStats(comp):\n",
    "    scoreboard = getScoreboard(conn, limit=dataLimit)\n",
    "    comp[\"RoleCount\"] = comp.sum(axis=1)\n",
    "    print(f\"Number of entries: {scoreboard.shape[0]}\")\n",
    "    print(f\"Number of entries with role: {comp['RoleCount'].sum()}\")\n",
    "    print(f\"Number of missing entries: {scoreboard.shape[0] - comp['RoleCount'].sum()}\")\n",
    "    print(f\"Percent missing: {(scoreboard.shape[0] - comp['RoleCount'].sum()) / scoreboard.shape[0] * 100:.2f}%\")\n",
    "\n",
    "getMissingPlayerStats(generateTeamCompList(getScoreboard(conn, limit=dataLimit)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6% Noise is nomral in most large ML models. Data featuring null values was removed causing this issue. Some team names were not imputed correctly leading to less agents on a team composition than normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD1vny2hfovz"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "module02_02_perceptron.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rosesenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
